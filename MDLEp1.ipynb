{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 1.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import collect_set, col, count\n",
    "from pyspark import SparkContext, SparkConf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf = SparkConf()\n",
    "sc = SparkContext(conf=conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"CSV with conditions\") \\\n",
    "    .config(\"spark.some.config.option\", \"some-value\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "spark.conf.set(\"spark.sql.execution.arrow.pyspark.enabled\", \"true\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a DataFrame of the conditions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- _c0: string (nullable = true)\n",
      " |-- _c1: string (nullable = true)\n",
      " |-- _c2: string (nullable = true)\n",
      " |-- _c3: string (nullable = true)\n",
      " |-- _c4: string (nullable = true)\n",
      " |-- _c5: string (nullable = true)\n",
      "\n",
      "+----------+----------+--------------------+--------------------+---------+--------------------+\n",
      "|       _c0|       _c1|                 _c2|                 _c3|      _c4|                 _c5|\n",
      "+----------+----------+--------------------+--------------------+---------+--------------------+\n",
      "|     START|      STOP|             PATIENT|           ENCOUNTER|     CODE|         DESCRIPTION|\n",
      "|2017-01-14|2017-03-30|09e4e8cb-29c2-4ef...|88e540ab-a7d7-47d...| 65363002|        Otitis media|\n",
      "|2012-09-15|2012-09-16|b0a03e8c-8d0f-424...|e89414dc-d0c6-478...|241929008|Acute allergic re...|\n",
      "|2018-06-17|2018-06-24|09e4e8cb-29c2-4ef...|c14325b0-f7ec-431...|444814009|Viral sinusitis (...|\n",
      "|2019-04-19|2019-09-26|09e4e8cb-29c2-4ef...|71af18ee-3157-408...| 65363002|        Otitis media|\n",
      "|2019-04-27|2019-05-18|09e4e8cb-29c2-4ef...|411d4eae-72d1-478...|444814009|Viral sinusitis (...|\n",
      "|2019-06-03|2019-08-02|09e4e8cb-29c2-4ef...|667a94d9-6aa1-4b6...| 33737001|     Fracture of rib|\n",
      "|2014-11-09|2014-11-30|b0a03e8c-8d0f-424...|53431016-43c6-46b...|444814009|Viral sinusitis (...|\n",
      "|2015-01-04|2015-01-18|b0a03e8c-8d0f-424...|fb838ab5-2805-41c...| 10509002|Acute bronchitis ...|\n",
      "|2015-03-26|      null|b0a03e8c-8d0f-424...|fbc7efee-c52c-4d4...|233678006|    Childhood asthma|\n",
      "|2015-08-04|2015-08-14|b0a03e8c-8d0f-424...|2c912168-e7c9-403...|195662009|Acute viral phary...|\n",
      "|2017-03-25|      null|b0a03e8c-8d0f-424...|c7b8d2e7-7503-420...|232353008|Perennial allergi...|\n",
      "|2017-07-06|2017-07-19|b0a03e8c-8d0f-424...|d80ec843-b8a0-4a6...|195662009|Acute viral phary...|\n",
      "|1997-07-15|2013-07-13|5420ae87-24c8-4ed...|48cf8d6c-42fd-4a0...|446096008|Perennial allergi...|\n",
      "|2011-12-07|2011-12-21|5420ae87-24c8-4ed...|e3339c56-7735-4cf...|284551006|  Laceration of foot|\n",
      "|2013-11-10|2013-11-24|5420ae87-24c8-4ed...|f6161868-7e9b-471...|283371005|Laceration of for...|\n",
      "|2016-09-24|2017-04-29|5420ae87-24c8-4ed...|0f531593-2c53-461...| 72892002|    Normal pregnancy|\n",
      "|2017-10-15|2017-10-22|5420ae87-24c8-4ed...|52d0d19a-7930-4b5...|444814009|Viral sinusitis (...|\n",
      "|2018-07-20|2018-07-29|5420ae87-24c8-4ed...|aefa8d2e-815f-43d...|195662009|Acute viral phary...|\n",
      "|2014-04-27|      null|bf1f30f2-27de-4b5...|14595c35-2966-465...|162864005|Body mass index 3...|\n",
      "+----------+----------+--------------------+--------------------+---------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = spark.read.csv(\"dataset/conditions.csv\")\n",
    "df.printSchema()\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---------+\n",
      "|             PATIENT|     CODE|\n",
      "+--------------------+---------+\n",
      "|09e4e8cb-29c2-4ef...| 65363002|\n",
      "|b0a03e8c-8d0f-424...|241929008|\n",
      "|09e4e8cb-29c2-4ef...|444814009|\n",
      "|09e4e8cb-29c2-4ef...| 65363002|\n",
      "|09e4e8cb-29c2-4ef...|444814009|\n",
      "|09e4e8cb-29c2-4ef...| 33737001|\n",
      "|b0a03e8c-8d0f-424...|444814009|\n",
      "|b0a03e8c-8d0f-424...| 10509002|\n",
      "|b0a03e8c-8d0f-424...|233678006|\n",
      "|b0a03e8c-8d0f-424...|195662009|\n",
      "|b0a03e8c-8d0f-424...|232353008|\n",
      "|b0a03e8c-8d0f-424...|195662009|\n",
      "|5420ae87-24c8-4ed...|446096008|\n",
      "|5420ae87-24c8-4ed...|284551006|\n",
      "|5420ae87-24c8-4ed...|283371005|\n",
      "|5420ae87-24c8-4ed...| 72892002|\n",
      "|5420ae87-24c8-4ed...|444814009|\n",
      "|5420ae87-24c8-4ed...|195662009|\n",
      "|bf1f30f2-27de-4b5...|162864005|\n",
      "|bf1f30f2-27de-4b5...|283385000|\n",
      "+--------------------+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Data_list = [\"START\",\"STOP\",\"PATIENT\",\"ENCOUNTER\",\"CODE\",\"DESCRIPTION\"]\n",
    " \n",
    "df = df.toDF(*Data_list)\n",
    "df=df.filter(df.START !=\"START\")\n",
    "\n",
    "df_Names=df\n",
    "df_Names=df_Names.drop(*['START','STOP','PATIENT','ENCOUNTER'])\n",
    "df_Names=df_Names.dropDuplicates()\n",
    "\n",
    "df=df.drop(*['START','STOP','ENCOUNTER','DESCRIPTION'])\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---------+\n",
      "|             PATIENT|     CODE|\n",
      "+--------------------+---------+\n",
      "|09e4e8cb-29c2-4ef...| 65363002|\n",
      "|b0a03e8c-8d0f-424...|241929008|\n",
      "|09e4e8cb-29c2-4ef...|444814009|\n",
      "|09e4e8cb-29c2-4ef...| 65363002|\n",
      "|09e4e8cb-29c2-4ef...|444814009|\n",
      "|09e4e8cb-29c2-4ef...| 33737001|\n",
      "|b0a03e8c-8d0f-424...|444814009|\n",
      "|b0a03e8c-8d0f-424...| 10509002|\n",
      "|b0a03e8c-8d0f-424...|233678006|\n",
      "|b0a03e8c-8d0f-424...|195662009|\n",
      "|b0a03e8c-8d0f-424...|232353008|\n",
      "|b0a03e8c-8d0f-424...|195662009|\n",
      "|5420ae87-24c8-4ed...|446096008|\n",
      "|5420ae87-24c8-4ed...|284551006|\n",
      "|5420ae87-24c8-4ed...|283371005|\n",
      "|5420ae87-24c8-4ed...| 72892002|\n",
      "|5420ae87-24c8-4ed...|444814009|\n",
      "|5420ae87-24c8-4ed...|195662009|\n",
      "|bf1f30f2-27de-4b5...|162864005|\n",
      "|bf1f30f2-27de-4b5...|283385000|\n",
      "+--------------------+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = df.dropna()  #confirmar depois com tudo\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a DataFrame and RDD of the Baskets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|items                                                                                                                                                                   |\n",
      "+------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|[703151001, 70704007, 65363002, 128613002, 192127007, 444814009, 232353008, 195662009]                                                                                  |\n",
      "|[59621000, 368581000119106, 80394007, 15777000, 55822004, 44054006, 271737000, 26929004, 88805009, 302870006, 237602007, 1551000119108, 444814009, 195662009, 422034002]|\n",
      "|[271737000, 201834006, 40055000, 10509002, 19169002, 444814009, 15777000, 55822004]                                                                                     |\n",
      "|[72892002, 10509002, 65363002, 444814009, 301011002]                                                                                                                    |\n",
      "|[271737000, 367498001, 10509002, 15777000, 55822004, 239873007]                                                                                                         |\n",
      "|[271737000, 72892002, 198992004, 43878008, 10509002, 444814009]                                                                                                         |\n",
      "|[162864005, 271737000, 72892002, 40055000, 19169002]                                                                                                                    |\n",
      "|[162864005, 271737000, 64859006, 62106007, 40055000, 195662009, 15777000, 55822004]                                                                                     |\n",
      "|[162864005, 307731004, 254837009, 59621000, 88805009, 10509002, 444814009]                                                                                              |\n",
      "|[271737000, 26929004, 59621000, 40055000, 403191005, 10509002, 444814009, 15777000, 233604007, 68496003]                                                                |\n",
      "|[254837009, 59621000, 88805009, 444814009]                                                                                                                              |\n",
      "|[70704007, 65363002]                                                                                                                                                    |\n",
      "|[162864005, 10509002, 195662009, 444814009, 55822004]                                                                                                                   |\n",
      "|[370247008, 53741008, 65966004, 429007001, 65363002, 410429000]                                                                                                         |\n",
      "|[40275004, 72892002, 40055000, 263102004, 195662009, 15777000, 44465007, 301011002]                                                                                     |\n",
      "|[271737000, 10509002, 444814009, 15777000, 55822004]                                                                                                                    |\n",
      "|[162864005, 283371005, 10509002, 19169002, 444814009]                                                                                                                   |\n",
      "|[703151001, 36971009, 40055000, 128613002, 195662009, 444814009, 44465007]                                                                                              |\n",
      "|[84757009, 370247008, 703151001, 70704007, 128613002, 10509002, 444814009, 44465007, 39848009]                                                                          |\n",
      "|[87433001, 429007001, 444814009, 195662009, 410429000]                                                                                                                  |\n",
      "+------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "baskets = df.groupBy('PATIENT').agg(collect_set('CODE').alias('items'))\n",
    "baskets.createOrReplaceTempView('baskets')\n",
    "baskets=baskets.drop('PATIENT')\n",
    "baskets.show(20,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['703151001',\n",
       "  '70704007',\n",
       "  '65363002',\n",
       "  '128613002',\n",
       "  '192127007',\n",
       "  '444814009',\n",
       "  '232353008',\n",
       "  '195662009'],\n",
       " ['59621000',\n",
       "  '368581000119106',\n",
       "  '80394007',\n",
       "  '15777000',\n",
       "  '55822004',\n",
       "  '44054006',\n",
       "  '271737000',\n",
       "  '26929004',\n",
       "  '88805009',\n",
       "  '302870006',\n",
       "  '237602007',\n",
       "  '1551000119108',\n",
       "  '444814009',\n",
       "  '195662009',\n",
       "  '422034002'],\n",
       " ['271737000',\n",
       "  '201834006',\n",
       "  '40055000',\n",
       "  '10509002',\n",
       "  '19169002',\n",
       "  '444814009',\n",
       "  '15777000',\n",
       "  '55822004'],\n",
       " ['72892002', '10509002', '65363002', '444814009', '301011002'],\n",
       " ['271737000', '367498001', '10509002', '15777000', '55822004', '239873007'],\n",
       " ['271737000', '72892002', '198992004', '43878008', '10509002', '444814009'],\n",
       " ['162864005', '271737000', '72892002', '40055000', '19169002'],\n",
       " ['162864005',\n",
       "  '271737000',\n",
       "  '64859006',\n",
       "  '62106007',\n",
       "  '40055000',\n",
       "  '195662009',\n",
       "  '15777000',\n",
       "  '55822004'],\n",
       " ['162864005',\n",
       "  '307731004',\n",
       "  '254837009',\n",
       "  '59621000',\n",
       "  '88805009',\n",
       "  '10509002',\n",
       "  '444814009'],\n",
       " ['271737000',\n",
       "  '26929004',\n",
       "  '59621000',\n",
       "  '40055000',\n",
       "  '403191005',\n",
       "  '10509002',\n",
       "  '444814009',\n",
       "  '15777000',\n",
       "  '233604007',\n",
       "  '68496003']]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BasquetRDD = baskets.rdd.flatMap(list) \n",
    "BasquetRDD.take(10) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Counting number of ocurrences of diseases in baskets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['703151001',\n",
       " '70704007',\n",
       " '65363002',\n",
       " '128613002',\n",
       " '192127007',\n",
       " '444814009',\n",
       " '232353008',\n",
       " '195662009',\n",
       " '59621000',\n",
       " '368581000119106',\n",
       " '80394007',\n",
       " '15777000',\n",
       " '55822004',\n",
       " '44054006',\n",
       " '271737000',\n",
       " '26929004',\n",
       " '88805009',\n",
       " '302870006',\n",
       " '237602007',\n",
       " '1551000119108']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CodesRDD=baskets.rdd.flatMap(lambda x: sum(x,[]))\n",
    "CodesRDD.take(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['128613002',\n",
       " '232353008',\n",
       " '195662009',\n",
       " '55822004',\n",
       " '302870006',\n",
       " '237602007',\n",
       " '201834006',\n",
       " '40055000',\n",
       " '19169002',\n",
       " '307731004']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Unique = CodesRDD.distinct()\n",
    "Unique.take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('128613002', 42693),\n",
       " ('232353008', 31036),\n",
       " ('195662009', 524692),\n",
       " ('55822004', 133442),\n",
       " ('302870006', 75992),\n",
       " ('237602007', 74395),\n",
       " ('201834006', 25426),\n",
       " ('40055000', 250239),\n",
       " ('19169002', 201894),\n",
       " ('307731004', 17220),\n",
       " ('53741008', 68517),\n",
       " ('65966004', 43961),\n",
       " ('84757009', 22352),\n",
       " ('79586000', 25783),\n",
       " ('398254007', 22959),\n",
       " ('236077008', 4422),\n",
       " ('262574004', 7629),\n",
       " ('97331000119101', 4291),\n",
       " ('707577004', 177),\n",
       " ('425048006', 1)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CountRDD = CodesRDD.map(lambda item: (item, 1))\n",
    "CountRDD = CountRDD.reduceByKey(lambda a,b: a+b)\n",
    "CountRDD.take(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('128613002', 42693),\n",
       " ('232353008', 31036),\n",
       " ('195662009', 524692),\n",
       " ('55822004', 133442),\n",
       " ('302870006', 75992),\n",
       " ('237602007', 74395),\n",
       " ('201834006', 25426),\n",
       " ('40055000', 250239),\n",
       " ('19169002', 201894),\n",
       " ('307731004', 17220)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Setting a support threshold of 1000\n",
    "# Aqui não tá 1000, tá 2, mas na versão com tudo faz-se com 1000\n",
    "CountFilterRDD=CountRDD.filter(lambda x: x[1] >= 1000) #Aqui 1000\n",
    "CountFilterRDD.take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(['128613002'], 42693),\n",
       " (['232353008'], 31036),\n",
       " (['195662009'], 524692),\n",
       " (['55822004'], 133442),\n",
       " (['302870006'], 75992),\n",
       " (['237602007'], 74395),\n",
       " (['201834006'], 25426),\n",
       " (['40055000'], 250239),\n",
       " (['19169002'], 201894),\n",
       " (['307731004'], 17220)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AprioriRDD=CountFilterRDD.map(lambda x: ([x[0]], x[1]))\n",
    "AprioriRDD.take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['128613002',\n",
       " '232353008',\n",
       " '195662009',\n",
       " '55822004',\n",
       " '302870006',\n",
       " '237602007',\n",
       " '201834006',\n",
       " '40055000',\n",
       " '19169002',\n",
       " '307731004']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CodeFilterRDD=CountFilterRDD.map(lambda x: x[0])\n",
    "CodeFilterRDD.take(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apriori Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove Replicas \n",
    "#Basquets with items that are in a diferent order, but with the same items\n",
    "\n",
    "def RemoveReplicas(item):\n",
    "\n",
    "    if(isinstance(item[0], tuple)):\n",
    "        x1 = item[0]\n",
    "        x2 = item[1]\n",
    "    else:\n",
    "        x1 = [item[0]]\n",
    "        x2 = item[1]\n",
    "\n",
    "    if(any(x == x2 for x in x1) == False):\n",
    "        a = list(x1)\n",
    "        a.append(x2)\n",
    "        a.sort()\n",
    "        result = tuple(a)\n",
    "        return result \n",
    "    else:\n",
    "        return x1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SumOp(x,y):\n",
    "    return x+y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "\n",
      "Combine\n",
      "[('195662009', '398254007'), ('232353008', '236077008'), ('302870006', '398254007'), ('128613002', '230265002'), ('195662009', '36971009'), ('237602007', '65363002'), ('53741008', '65363002'), ('19169002', '38822007'), ('65966004', '713197008'), ('283371005', '398254007')]\n",
      "\n",
      "Combine2\n",
      "[(('444814009', '79586000'), 17253), (('19169002', '239873007'), 17667), (('195662009', '6072007'), 2061), (('302870006', '703151001'), 2466), (('22298006', '65966004'), 1132), (('26929004', '88805009'), 4396), (('40055000', '424132000'), 3976), (('239872002', '65966004'), 1089), (('196416002', '64859006'), 3323), (('5602001', '88805009'), 1191)]\n",
      "\n",
      "CodeFilterRDD\n",
      "[('444814009', '79586000'), ('19169002', '239873007'), ('195662009', '6072007'), ('302870006', '703151001'), ('22298006', '65966004'), ('26929004', '88805009'), ('40055000', '424132000'), ('239872002', '65966004'), ('196416002', '64859006'), ('5602001', '88805009')]\n",
      "\n",
      "3\n",
      "\n",
      "Combine\n",
      "[('197927001', '26929004', '88805009'), ('124171000119105', '206523001', '428251008'), ('124171000119105', '314994000', '428251008'), ('124171000119105', '190905008', '428251008'), ('448417001', '5602001', '88805009'), ('230690007', '35999006', '424132000'), ('444814009', '65275009', '79586000'), ('230690007', '302870006', '703151001'), ('161622006', '196416002', '64859006'), ('232353008', '307731004', '428251008')]\n",
      "\n",
      "Combine2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:KeyboardInterrupt while sending command.\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/spark/python/lib/py4j-0.10.9.3-src.zip/py4j/java_gateway.py\", line 1038, in send_command\n",
      "    response = connection.send_command(command)\n",
      "  File \"/usr/local/spark/python/lib/py4j-0.10.9.3-src.zip/py4j/clientserver.py\", line 475, in send_command\n",
      "    answer = smart_decode(self.stream.readline()[:-1])\n",
      "  File \"/opt/conda/lib/python3.9/socket.py\", line 704, in readinto\n",
      "    return self._sock.recv_into(b)\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0mTraceback (most recent call last)",
      "Input \u001b[0;32mIn [17]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m Combine2 \u001b[38;5;241m=\u001b[39m Combine2\u001b[38;5;241m.\u001b[39mfilter(\u001b[38;5;28;01mlambda\u001b[39;00m x: x[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1000\u001b[39m) \u001b[38;5;66;03m#Aqui 1000 em vez de 2\u001b[39;00m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCombine2\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 24\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mCombine2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtake\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     27\u001b[0m AprioriRDD \u001b[38;5;241m=\u001b[39m AprioriRDD\u001b[38;5;241m.\u001b[39munion(Combine2)\n",
      "File \u001b[0;32m/usr/local/spark/python/pyspark/rdd.py:1568\u001b[0m, in \u001b[0;36mRDD.take\u001b[0;34m(self, num)\u001b[0m\n\u001b[1;32m   1565\u001b[0m         taken \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1567\u001b[0m p \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mrange\u001b[39m(partsScanned, \u001b[38;5;28mmin\u001b[39m(partsScanned \u001b[38;5;241m+\u001b[39m numPartsToTry, totalParts))\n\u001b[0;32m-> 1568\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcontext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrunJob\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtakeUpToNumLeft\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mp\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1570\u001b[0m items \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m res\n\u001b[1;32m   1571\u001b[0m partsScanned \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m numPartsToTry\n",
      "File \u001b[0;32m/usr/local/spark/python/pyspark/context.py:1227\u001b[0m, in \u001b[0;36mSparkContext.runJob\u001b[0;34m(self, rdd, partitionFunc, partitions, allowLocal)\u001b[0m\n\u001b[1;32m   1223\u001b[0m \u001b[38;5;66;03m# Implementation note: This is implemented as a mapPartitions followed\u001b[39;00m\n\u001b[1;32m   1224\u001b[0m \u001b[38;5;66;03m# by runJob() in order to avoid having to pass a Python lambda into\u001b[39;00m\n\u001b[1;32m   1225\u001b[0m \u001b[38;5;66;03m# SparkContext#runJob.\u001b[39;00m\n\u001b[1;32m   1226\u001b[0m mappedRDD \u001b[38;5;241m=\u001b[39m rdd\u001b[38;5;241m.\u001b[39mmapPartitions(partitionFunc)\n\u001b[0;32m-> 1227\u001b[0m sock_info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jvm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mPythonRDD\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrunJob\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jsc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmappedRDD\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jrdd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpartitions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1228\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(_load_from_socket(sock_info, mappedRDD\u001b[38;5;241m.\u001b[39m_jrdd_deserializer))\n",
      "File \u001b[0;32m/usr/local/spark/python/lib/py4j-0.10.9.3-src.zip/py4j/java_gateway.py:1320\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1313\u001b[0m args_command, temp_args \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_args(\u001b[38;5;241m*\u001b[39margs)\n\u001b[1;32m   1315\u001b[0m command \u001b[38;5;241m=\u001b[39m proto\u001b[38;5;241m.\u001b[39mCALL_COMMAND_NAME \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1316\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_header \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1317\u001b[0m     args_command \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1318\u001b[0m     proto\u001b[38;5;241m.\u001b[39mEND_COMMAND_PART\n\u001b[0;32m-> 1320\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgateway_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend_command\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcommand\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1321\u001b[0m return_value \u001b[38;5;241m=\u001b[39m get_return_value(\n\u001b[1;32m   1322\u001b[0m     answer, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget_id, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname)\n\u001b[1;32m   1324\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n",
      "File \u001b[0;32m/usr/local/spark/python/lib/py4j-0.10.9.3-src.zip/py4j/java_gateway.py:1038\u001b[0m, in \u001b[0;36mGatewayClient.send_command\u001b[0;34m(self, command, retry, binary)\u001b[0m\n\u001b[1;32m   1036\u001b[0m connection \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_connection()\n\u001b[1;32m   1037\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1038\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mconnection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend_command\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcommand\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1039\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m binary:\n\u001b[1;32m   1040\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m response, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_connection_guard(connection)\n",
      "File \u001b[0;32m/usr/local/spark/python/lib/py4j-0.10.9.3-src.zip/py4j/clientserver.py:475\u001b[0m, in \u001b[0;36mClientServerConnection.send_command\u001b[0;34m(self, command)\u001b[0m\n\u001b[1;32m    473\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    474\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 475\u001b[0m         answer \u001b[38;5;241m=\u001b[39m smart_decode(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreadline\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m])\n\u001b[1;32m    476\u001b[0m         logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAnswer received: \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(answer))\n\u001b[1;32m    477\u001b[0m         \u001b[38;5;66;03m# Happens when a the other end is dead. There might be an empty\u001b[39;00m\n\u001b[1;32m    478\u001b[0m         \u001b[38;5;66;03m# answer before the socket raises an error.\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/socket.py:704\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    702\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m    703\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 704\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    705\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[1;32m    706\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout_occurred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for k in[2,3]:\n",
    "    print(k)\n",
    "    print('')\n",
    "    \n",
    "    Combine = CodeFilterRDD.cartesian(Unique)\n",
    "    Combine = Combine.map(lambda x: RemoveReplicas(x))\n",
    "  \n",
    "    Combine = Combine.filter(lambda x: len(x) == k)\n",
    "    Combine = Combine.distinct()\n",
    "     \n",
    "    print('Combine')\n",
    "    print(Combine.take(10))\n",
    "    print('')\n",
    "    \n",
    "    Combine2 = Combine.cartesian(BasquetRDD)\n",
    "    Combine2 = Combine2.filter(lambda y: all(x in y[1] for x in y[0]))\n",
    "    \n",
    "    Combine2 = Combine2.map(lambda x: x[0])\n",
    "    Combine2 = Combine2.map(lambda x: (x , 1))\n",
    "    Combine2 = Combine2.reduceByKey(SumOp)\n",
    "    Combine2 = Combine2.filter(lambda x: x[1] >= 1000) #Aqui 1000 em vez de 2\n",
    "    \n",
    "    print('Combine2')\n",
    "    print(Combine2.take(10))\n",
    "    print('')\n",
    "\n",
    "    AprioriRDD = AprioriRDD.union(Combine2)\n",
    "    \n",
    "    Combine2 = Combine2.map(lambda x: x[0])\n",
    "    CodeFilterRDD = Combine2\n",
    "    \n",
    "    print('CodeFilterRDD')\n",
    "    print(CodeFilterRDD.take(10))\n",
    "    print('')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "AprioriFilter=AprioriRDD.filter(lambda x: len(x[0])!=1)\n",
    "AprioriFilter2=AprioriFilter.filter(lambda x: len(x[0])==2)\n",
    "AprioriFilter3=AprioriFilter.filter(lambda x: len(x[0])==3)\n",
    "print('k=2')\n",
    "print(AprioriFilter2.collect())\n",
    "print(' ')\n",
    "print('k=3')\n",
    "print(AprioriFilter3.collect())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 1.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Dictionarys to search the quantaty of deceases quantaty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "countbaskets=baskets.count()\n",
    "\n",
    "AprioriDict1=CountFilterRDD.collectAsMap()\n",
    "AprioriFilter22=AprioriFilter2.map(lambda item: ((item[0][1],item[0][0]),item[1]))\n",
    "AprioriFilter22.take(10)\n",
    "\n",
    "AprioriDict2=AprioriFilter2.collectAsMap()\n",
    "AprioriDict22=AprioriFilter22.collectAsMap()\n",
    "AprioriDict2.update(AprioriDict22)\n",
    "\n",
    "print(AprioriDict1)\n",
    "print(AprioriDict2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(countbaskets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Confidence Interval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check Items sets includes at least one comman item \n",
    "\n",
    "def CheckItemSets(item_1 , item_2):\n",
    "\n",
    "    if(len(item_1) > len(item_2)):\n",
    "        return all(any(k == l for k in item_1 ) for l in item_2)\n",
    "    else:\n",
    "        return all(any(k == l for k in item_2 ) for l in item_1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def FilterForConfidence(item , total):\n",
    "        \n",
    "    if(len(item[0][0]) > len(item[1][0])  ):\n",
    "        if(CheckItemSets(item[0][0] , item[1][0]) == False):\n",
    "            pass\n",
    "        else:\n",
    "            return (item)       \n",
    "    else:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CalculateConfidence(item):\n",
    "\n",
    "    # Parent item list\n",
    "    parent = set(item[0][0])\n",
    "        \n",
    "    # Child item list\n",
    "    if(isinstance(item[1][0] , str)):\n",
    "        child  = set([item[1][0]])\n",
    "    else:\n",
    "        child  = set(item[1][0])\n",
    "    # Parent and Child support values\n",
    "    parentSupport = item[0][1]\n",
    "    childSupport = item[1][1]\n",
    "    # Finds the item set confidence is going to be found\n",
    "\n",
    "    support = (parentSupport / childSupport)*100\n",
    "\n",
    "    return list([ list(child) ,  list(parent.difference(child)) , support ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def Interest(item):\n",
    "    if len(item[1])==1:\n",
    "        j=AprioriDict1[item[1][0]]\n",
    "    else:\n",
    "        j=AprioriDict2[tuple(item[1])]\n",
    "    interest=item[2]-((j/countbaskets)*100) #Aqui o *100 é para se for em percentagem, não sei se devia ser assim....\n",
    "    item.append(interest)\n",
    "    return item"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Lift(item):\n",
    "    if len(item[1])==1:\n",
    "        j=AprioriDict1[item[1][0]]\n",
    "    else:\n",
    "        j=AprioriDict2[tuple(item[1])]\n",
    "    lift=item[2]/((j/countbaskets)*100) #Aqui a cena do devimal ou percentagem again\n",
    "    item.append(lift)\n",
    "    return item"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standardised Lift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# deve tar mal os valores que dão tão muito estranhos\n",
    "\n",
    "def  StandardisedLift(item):\n",
    "    if len(item[1])==1:\n",
    "        j=AprioriDict1[item[1][0]]\n",
    "    else:\n",
    "        j=AprioriDict2[tuple(item[1])]\n",
    "    #print(j)\n",
    "        \n",
    "    if len(item[0])==1:\n",
    "        i=AprioriDict1[item[0][0]]\n",
    "    else:\n",
    "        i=AprioriDict2[tuple(item[0])]\n",
    "    #print(i)\n",
    "        \n",
    "    pi= i/countbaskets\n",
    "    pj= j/countbaskets\n",
    "    #print(pi, pj)\n",
    "    \n",
    "    l=[pi+pj-1,1/countbaskets]\n",
    "    #print(l)\n",
    "    \n",
    "    term=max(l)/(pi*pj)\n",
    "    #print(term)\n",
    "    \n",
    "    standardisedlift=(item[4]-term)/((1/(pi*pj))-term) #Aqui a cena do decimal ou percentagem again  #nãos sei se é max ou não\n",
    "    #print(standardisedlift)\n",
    "    item.append(standardisedlift)\n",
    "    return item"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Applying Statistics and organizing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calcuItems = AprioriRDD.cartesian(AprioriRDD)\n",
    "total = calcuItems.count()\n",
    "\n",
    "StatisticsRDD = calcuItems.filter(lambda item: FilterForConfidence(item , total))\n",
    "StatisticsRDD = StatisticsRDD.map(lambda item: CalculateConfidence(item))\n",
    "StatisticsRDD = StatisticsRDD.map(lambda item: Interest(item))\n",
    "StatisticsRDD = StatisticsRDD.map(lambda item: Lift(item))\n",
    "StatisticsRDD = StatisticsRDD.map(lambda item: StandardisedLift(item))\n",
    "StatisticsRDD.take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "isto agora tá a dar conjunto vazio porque o standard lift tá mal\n",
    "StatisticsRDD=StatisticsRDD.filter(lambda item: item[5] >= 0.2) \n",
    "StatisticsRDD.take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Names.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Names = df_Names.toPandas()\n",
    "  \n",
    "# Convert the dataframe into \n",
    "# dictionary\n",
    "Dict_Names=dict(df_Names.values)\n",
    "  \n",
    "# Print the dictionary\n",
    "print(Dict_Names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CodeToName(item):\n",
    "    \n",
    "    if len(item[0])==1:\n",
    "        item[0][0]=Dict_Names[item[0][0]]\n",
    "    else:\n",
    "        item[0][0]=Dict_Names[item[0][0]]\n",
    "        item[0][1]=Dict_Names[item[0][1]]\n",
    "        \n",
    "    if len(item[1])==1:\n",
    "        item[1][0]=Dict_Names[item[1][0]]\n",
    "    else:\n",
    "        item[1][0]=Dict_Names[item[1][0]]\n",
    "        item[1][1]=Dict_Names[item[1][1]]\n",
    "        \n",
    "    return item\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "StatisticsRDD = StatisticsRDD.map(lambda item: CodeToName(item))\n",
    "StatisticsRDD.take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Organized(item):\n",
    "    if len(item[0])==1:\n",
    "        item[0]=item[0][0]\n",
    "    else:\n",
    "        item[0]=tuple(item[0])\n",
    "        \n",
    "    if len(item[1])==1:\n",
    "        item[1]=item[1][0]\n",
    "    else:\n",
    "        item[1]=tuple(item[1])\n",
    "        \n",
    "    item[2] = round(item[2], 2)\n",
    "    item[3] = round(item[3], 2)\n",
    "    item[4] = round(item[4], 2)\n",
    "    item[5] = round(item[5], 2)\n",
    "    \n",
    "    return item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "StatisticsRDD = StatisticsRDD.map(lambda item: Organized(item))\n",
    "StatisticsRDD.take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "StatisticsRDD=StatisticsRDD.sortBy(lambda x: x[5])\n",
    "StatisticsRDD.take(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving to a text file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Final_df = pd.DataFrame(StatisticsRDD.collect(), columns = [\"I\",\"j\",\"Confidence\",\"Interest\",\"Lift\",\"Standerdized Lift\"])\n",
    "Final_df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Final_df.to_csv('Conditions Rules.txt', index=None, sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Repositório fixe para o apriori\n",
    "\n",
    "https://github.com/sergencansiz/apriori-pyspark/blob/master/AprioriPySpark.py\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e61b0395c6402dd6e89f7a5082a90c12afe336de25fb448ff9b187ddb8b4ce0d"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
